# Exercise 3: Add AI Chat to your application

> [!Note]
> Goal: Add Azure Open AI (AOAI) chat functionality and a LLM, then connect the chat interface in your app to AOAI.

## Module overview

In [Exercise-2](/Lab-Instructions/2.Exercise-2.md), you added Azure Search AI and made sure your app can connect to the Search service end point. You have also created an index and uploaded some sample data to the Search service.

In this module, you are going to run `azd add` to add Azure Open AI so that you can learn how your chat result is affected when you add grounding data to chat.

> [!Note]
> Time to complete: 25 minutes

## Instructions

1. Make sure you are still in the **/src** folder.
1. Run `azd add`
    * Select "AI"
    * Select "Azure OpenAI model"
    * Select "Chat (GPT)"
    * Select "gpt-4o 2024-11-20"
    * For this lab exercise, When prompted to provide a name, hit enter to select the default value which is "gpt-4o" 
    * Make sure your service uses the newly added resource by typing \<space> to select.
    ![Connect service to gpt-4o](/Lab-Instructions/Images/3.ConnectServicetoAOAI.png)
    * Type "Y" or simply hit \<enter> to accept changes to azure.yaml.
    * Select `Yes` to provision the changes.
1. Provision can take 5-8 minutes.
1. While waiting, use GitHub Copilot for Azure to learn more about AI models
    
    Sample prompt:      
    "@azure can you provide a comparison of AI models that are appropriate for Azure Open AI and a chat app like the one in this lab?"
    
    We use the OpenAI Chat GPT-4o model. The Azure OpenAI Chat GPT-4o model is a powerful language model available through the Azure OpenAI Service. This model is designed for advanced conversational AI tasks.

    The Chat GPT-4o model is integrated with Azure's capabilities, providing scalability, security, and enterprise features. There are different variants like GPT-4o Mini, which is a lighter version, and GPT-4 Turbo with Vision, which includes vision capabilities, that you can use for your use case.

## Running the app and redeploy to Azure

We will skip running the app locally but similar to the previous exercise, if you want to do that, run `azd show gpt-4o` and set the environment variable. Reminder: Line 33 in app.py.

![app.py](/Lab-Instructions/Images/3.appcode.png)

## Running the app
If you didn't change any of the app code, you **do not need** to run `azd deploy`. 

**Hint**: you can always run `azd show` to get the end point of your app running on Azure if you don't already have it open.

1. Go to your app end point.
2. Under AI Hotel Recommendations, click the "Get Recommendations" button. Chat will say "I don't know".
3. Switch the "Use grounding with AI Search" toggle to on and click "Get Recommendations" button and you will see:

    ![Chat with grounding data](/Lab-Instructions/Images/3.chat-grounding.png)

4. You can ask Copilot to explain how this work too!
  Sample prompt: "@azure can you explain how does grounding data to search AI work for this app?"

## The Code

At this point, your azure.yaml should look like this:

``` yaml
# yaml-language-server: $schema=https://raw.githubusercontent.com/Azure/azure-dev/main/schemas/alpha/azure.yaml.json
name: src
metadata:
  template: azd-init@xxxx
services:
  src:
    project: .
    host: containerapp
    language: python
    docker:
      path: Dockerfile
resources:
  src:
    type: host.containerapp
    port: 5000
    uses:
      - search
      - gpt-4o
  search:
    type: ai.search
  gpt-4o:
    type: ai.openai.model
    model:
      name: gpt-4o
      version: "2024-11-20"
```

## Add a Foundry model 
The app has a toggle at the top right corner that allow you to switch the model to a Foundry model. 

![Foundry toggle](/Lab-Instructions/Images/3.foundrytoggle.png)

Let's use `azd add` and try and see how using a different model affect chat result? 

## Instructions

1. Make sure you are still in the **/src** folder.
1. Run `azd add`
    * Select "AI"
    * Select "Azure AI services model"
    * Select **Phi-4** (**app.py** has hardcoded the model to be Phi-4 for Foundry model)
    * Select **AIServices** for deployment kind.
    * Select **7** for version.
    * Make sure you type \<SPACE> to connect **src** to the new **ai-project** resource.
    * Type "Y" or simply hit \<enter> to accept changes to azure.yaml.
    * Select `Yes` to provision the changes. When prompted for the **phi47Location** parameter, use **East US 2**.
1. Provision can take 5-8 minutes.
1. While waiting, use GitHub Copilot for Azure to learn more about AI models.
    
    Sample prompt:      
    * "@azure how is Phi-4 model different from gpt-4o?"
    * "@azure why would I choose one over the other?"
    
If you successfully add a Foundry model, you can compare and see the difference!
![Comparison of models](/Lab-Instructions/Images/3.Comparision.png)

## Next
Now that you've added AI Chat to your application, head over to [Exercise 4](/Lab-Instructions/4.Exercise-4.md) to configure your applications so it's running optimally on Azure.

## All exercises

- [Exercise 1](/Lab-Instructions/1.exercise-deploy-app.md)
- [Exercise 2](/Lab-Instructions/2.exercise-ai-search.md)
- [Exercise 3](/Lab-Instructions/3.exercise-ai-chat.md)
- [Exercise 4](/Lab-Instructions/4.Exercise-4.md)
- [Exercise 5](/Lab-Instructions/5.Exercise-5.md)